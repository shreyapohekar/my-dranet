<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Concepts on DRANET</title><link>https://dranet.dev/docs/concepts/</link><description>Recent content in Concepts on DRANET</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 05 Jun 2025 11:20:46 +0000</lastBuildDate><atom:link href="https://dranet.dev/docs/concepts/index.xml" rel="self" type="application/rss+xml"/><item><title>Linux Network Namespaces and Interfaces</title><link>https://dranet.dev/docs/concepts/linux-network-interfaces/</link><pubDate>Thu, 05 Jun 2025 11:20:46 +0000</pubDate><guid>https://dranet.dev/docs/concepts/linux-network-interfaces/</guid><description>Network namespaces create isolated network stacks, including network devices, IP addresses, routing tables, rules , &amp;hellip; This separation is crucial for containerization.
Network namespaces also contain network devices that can live exactly on one network namespace:
physical network device can live in exactly one network namespace. When a network namespace is freed (i.e., when the last process in the namespace terminates), its physical network devices are moved back to the initial network namespace (not to the namespace of the parent of the process).</description></item><item><title>Making Networks Flexible</title><link>https://dranet.dev/docs/concepts/flexible-networks/</link><pubDate>Thu, 05 Jun 2025 11:20:46 +0000</pubDate><guid>https://dranet.dev/docs/concepts/flexible-networks/</guid><description>Think about how we build things. In the old days of IT, setting up a server was like building a detailed model airplane. Every piece had a specific part number and a precise spot where it had to be glued. The network card was eth0, and it was always eth0. If that changed, things broke.
Today, in the world of Kubernetes and the cloud, we build things more like we&amp;rsquo;re using Lego bricks.</description></item><item><title>Interface Status</title><link>https://dranet.dev/docs/concepts/interface-status/</link><pubDate>Sun, 25 May 2025 11:30:40 +0000</pubDate><guid>https://dranet.dev/docs/concepts/interface-status/</guid><description>Understanding Interface Status Output When DRANET allocates a network interface to a Pod via a ResourceClaim, it publishes the status of the allocated device within the ResourceClaim&amp;rsquo;s status field. This provides crucial insights into the readiness and configuration of the network interface from a Kubernetes perspective, adhering to the standardized device status defined in KEP-4817.
After a ResourceClaim is processed and a network device is allocated, its status is reflected under ResourceClaim.</description></item><item><title>Hardware Efficiency</title><link>https://dranet.dev/docs/concepts/hardware-efficiency/</link><pubDate>Sun, 25 May 2025 11:20:46 +0000</pubDate><guid>https://dranet.dev/docs/concepts/hardware-efficiency/</guid><description>Scaling Out, Not Just Up The journey of computing has always been a quest for greater efficiency. From hypervisors carving up physical servers to containers offering even more granular control, the pattern is clear. Now, with AI/ML and High-Performance Computing (HPC) taking center stage, a new frontier in resource optimization is opening up, especially around specialized hardware like high-performance networking.
This is where solutions like DRANET, a Kubernetes network driver, are making significant strides.</description></item><item><title>RDMA</title><link>https://dranet.dev/docs/concepts/rdma/</link><pubDate>Sun, 25 May 2025 11:20:46 +0000</pubDate><guid>https://dranet.dev/docs/concepts/rdma/</guid><description>Understanding RDMA Components in Linux RDMA (Remote Direct Memory Access) is a powerful technology enabling applications to directly read from or write to memory on a remote machine without involving the CPU, caches, or operating system of either machine during the data transfer. This achieves ultra-low latency and high throughput, making it ideal for high-performance computing (HPC), AI/ML, and storage.
In a Linux system, the RDMA ecosystem involves several interconnected components:</description></item><item><title>RDMA Device Handling</title><link>https://dranet.dev/docs/concepts/rdma-modes/</link><pubDate>Sun, 25 May 2025 11:20:46 +0000</pubDate><guid>https://dranet.dev/docs/concepts/rdma-modes/</guid><description>DRANET provides robust support for Remote Direct Memory Access (RDMA) devices, essential for high-performance computing (HPC) and AI/ML workloads that require ultra-low latency communication. DRANET&amp;rsquo;s RDMA implementation intelligently handles device allocation based on the host system&amp;rsquo;s RDMA network namespace mode.
RDMA Device Handling in DRANET DRANET manages three primary types of RDMA-related components for Pods:
RDMA Character Devices: These are user-space interfaces (e.g., /dev/infiniband/uverbsN, /dev/infiniband/rdma_cm) that user applications interact with to set up RDMA resources.</description></item><item><title>How It Works</title><link>https://dranet.dev/docs/concepts/howitworks/</link><pubDate>Thu, 19 Dec 2024 11:20:46 +0000</pubDate><guid>https://dranet.dev/docs/concepts/howitworks/</guid><description>The networking DRA driver uses GRPC to communicate with the Kubelet via the DRA API and the Container Runtime via NRI. This architecture facilitates the supportability and reduces the complexity of the solution, it also makes it fully compatible and agnostic of the existing CNI plugins in the cluster.
The DRA driver, once the Pod network namespaces has been created, will receive a GRPC call from the Container Runtime via NRI to execute the corresponding configuration.</description></item><item><title>References</title><link>https://dranet.dev/docs/concepts/references/</link><pubDate>Thu, 19 Dec 2024 11:20:46 +0000</pubDate><guid>https://dranet.dev/docs/concepts/references/</guid><description>The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking - This paper introduces the Kubernetes Network Driver model and provides a detailed performance evaluation of DRANET, demonstrating significant bandwidth improvements for AI/ML workloads. The Challenges of AI/ML Multi-Node Workloads in Kubernetes - Antonio Ojea, Google - Regular SIG Network Meeting for 2025-07-17 Kubernetes Network Drivers, Antonio Ojea, Presentation KEP 3063 - Dynamic Resource Allocation #306
KEP 3695 - DRA: structured parameters #438</description></item></channel></rss>